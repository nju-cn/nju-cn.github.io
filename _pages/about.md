---
permalink: /
title: "HOMEPAGE"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
h1 { font: 26pt Microsoft YaHei !important; }
h2 { font: 22pt Microsoft YaHei !important; }
h3 { font: 16pt Microsoft YaHei !important; }
p { font: 14pt kai !important; }
</style>

<style>   h1, h2, h3, h4, h5, h6 {     border-bottom: none;   } </style>

<style>
    p{
        text-align:justify;
        text-justify:inter-word;
    }
</style>





## **ABOUT** 

I am now a Lecturer in Department of Computer Science and Technology in **[SooChow University](https://scst.suda.edu.cn/)**, and working in the team leaded by Prof.  <a href="https://scst.suda.edu.cn/0e/37/c30767a527927/page.htm" >**He Huang**</a>. Before that, I obtained my Ph.D. degree in Department of Computer Science and Technology in [**Nanjing University**](https://cs.nju.edu.cn/main.htm), Nanjing in 2024, advised by Prof. [**Sanglu Lu**](https://cs.nju.edu.cn/58/1e/c2639a153630/page.htm) and [**Sheng Zhang**](https://cs.nju.edu.cn/c9/e4/c2640a51684/page.htm).



## **RESEARCH INTERESTS** 

Focusing on optimizing edge video inference systems, my research aims to achieve low-latency, low-power consumption, and  high-performance video inference in resource-constrained edge  environments. Specifically, my research encompasses the following three  core sub-directions:

**<font color="red">Adaptive Video Configuration: </font>** In edge computing environments, due to hardware limitations (such as computational power, memory, and  battery life), network bandwidth uncertainty, and video content  diversity, traditional fixed-configuration methods pose significant  challenges to the real-time performance and accuracy of video inference. Thus, I explore dynamically adjusting video configurations (such as  resolution, frame rate, compression rate, bitrate, etc.) to optimize  system performance under varying resource availability while meeting  latency and accuracy requirements. 

**<font color="red">Cloud-Edge-End Collaboration Mechanism: </font>**Given the limited  resources of edge devices and the computational and storage-intensive  nature of video inference tasks (such as video analysis and  enhancement), I investigate task-layered architectures based on the  complexity and timeliness of video tasks. This involves intelligently  distributing tasks across the cloud, edge, and end devices. For  instance, edge devices can utilize their CPUs for video preprocessing  (such as frame filtering, ROI extraction, result caching, etc.), edge  servers perform the actual video inference, while the cloud dynamically  trains and fine-tunes models based on video content and lightweight  models through pruning and compression techniques. 

**<font color="red">Collaborative Inference with Heterogeneous Devices: </font>**Single-device inference cannot guarantee real-time performance. With the widespread  deployment of devices like smart cameras, I explore collaborative  inference among multiple heterogeneous devices to accelerate inference.  This collaboration can take two forms: (1) **Model partitioning and  distributed deployment**: Based on the runtime status of heterogeneous  devices and the size of intermediate model data, the model is divided  into multiple parts and deployed across several heterogeneous devices.  This pipelined approach increases throughput and reduces average  processing latency. (2) **Data partitioning and parallel offloading**:  Data is partitioned based on video features and offloaded to  heterogeneous devices for parallel inference, thus accelerating the  inference process.

## **RECRUITING**

I am looking for well motivated students to work on  cutting-edge research projects. Both undergraduate and graduate students are welcome!

***<font color="red">2025年我组有空缺硕士指标，欢迎同学们联系！</font>***

## **NEWS** 

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2024/11/9)</strong> <strong style="color: blue;">Ning Chen</strong> is selected for the <strong>CCF 2024 Networks and Data Communications Specialised Committee's Outstanding Doctoral Dissertation Degree Incentive Scheme!</strong>
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2024/7/5)</strong> <strong style="color: blue;">Ning Chen</strong> joins <strong>Soochow University as an outstanding young scholar</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2024/5/28)</strong> <strong style="color: blue;">Ning Chen</strong> passes the <strong>Doctoral Dissertation Defence at Nanjing University</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2024/2/12)</strong> Our paper <strong style="color: blue; text-decoration: underline;"> MACRO: Incentivizing Multi-leader Game-based Pareto-efficient Crowdsourcing for Video Analytics</strong> is accepted by <strong>ICDE 2024</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2023/12/13)</strong> Our paper <strong style="color: blue; text-decoration: underline;"> AdaPyramid: Adaptive Pyramid for Accelerating High-resolution Object Detection on Edge Devices</strong> is accepted by <strong>TMC</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;style=height: 40px;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2023/12/1)</strong> Our paper <strong style="color: blue; text-decoration: underline;">  VisFlow: Adaptive Content-Aware Video Analytics on Collaborative Cameras</strong> is accepted by <strong>INFOCOM 2024</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2023/12/1)</strong> Our paper <strong style="color: blue; text-decoration: underline;">  TileSR: Accelerate On-Device Super-Resolution with Parallel Offloading in Tile Granularity</strong> is accepted by <strong>INFOCOM 2024</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2023/6/12)</strong> Our paper <strong style="color: blue; text-decoration: underline;">  ViChaser: Chase Your Viewpoint for Live Video Streaming with Block-Oriented Super-Resolution</strong> is accepted by <strong>ToN</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2023/2/14)</strong> Our paper <strong style="color: blue; text-decoration: underline;">  Scheduling In-Band Network Telemetry with Convergence-Preserving Federated Learning</strong> is accepted by <strong>ToN</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2023/1/19)</strong> Our paper <strong style="color: blue; text-decoration: underline;">  Dependent Task offloading and Service Caching with State Management for Mobile Edge Computing</strong> is accepted by <strong>ICC 2023</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2022/12/2)</strong> Our paper <strong style="color: blue; text-decoration: underline;">  ResMap: Exploiting Sparse Residual Feature Map for Accelerating Cross-Edge Video Analytics</strong> is accepted by <strong>INFOCOM 2023</strong>!
    </span>
</div>

<div style="display: flex; align-items: center;font-family: Times New Roman, sans-serif;">
    <img src="http://nju-cn.github.io/images/new_blue.gif" alt="NEW" style="margin-right: 8px;width: 45px; height: 45px;">
    <span style="font-size: 14px;">
        <strong style="color: red;">(2022/12/2)</strong> Our paper <strong style="color: blue; text-decoration: underline;">  Crowd^2: Multi-agent Bandit-based Dispatch for Video Analytics upon Crowdsourcing</strong> is accepted by <strong>INFOCOM 2023</strong>!
    </span>
</div>


## **SELECTED PUBLICATIONS**

<style>
hr:nth-of-type(1) {
  border-width: 5px 0 0 0 !important;
  border-color: orange !important;
}
hr:nth-of-type(2) {
  border-width: 5px 0 0 0 !important;
  border-color: orange !important;
}
    hr:nth-of-type(3) {
  border-width: 5px 0 0 0 !important;
  border-color: orange !important;
}
     hr:nth-of-type(4) {
  border-width: 5px 0 0 0 !important;
  border-color: orange !important;
}
    hr:nth-of-type(5) {
  border-width: 5px 0 0 0 !important;
  border-color: orange !important;
}
</style>


* **ViChaser: Chase Your Viewpoint for Live Video Streaming with Block-Oriented Super Resolution** 

  Accepted by  IEEE/ACM **TON** 2023, **CCF A**       <a href="http://nju-cn.github.io/files/TON_ViChaser.pdf" style="background: red; color: white;">link</a>

  **Ning Chen**, Sheng Zhang, Zhi Ma, Yu Chen, Yibo Jin, Jie Wu, Zhuzhong Qian, Yu Liang, and Sanglu Lu.

* **TileSR: Accelerate On-Device Super-Resolution with Parallel Offloading in Tile Granularity**

  Accepted by IEEE **INFOCOM** 2024, **CCF‑A**       <a href="http://nju-cn.github.io/files/TileSR_INFOCOM.pdf" style="background: red; color: white;">link</a>         <a href="http://nju-cn.github.io/files/Infocom2024.pptx" style="background: blue; color: white;">slides</a>

  **Ning Chen**, Sheng Zhang, Yu Liang, Jie Wu, Yu Chen, Yuting Yan, Zhuzhong Qian and Sanglu Lu.

* **ResMap: Exploiting Sparse Residual Feature Map for Accelerating Cross‑Edge Video Analytics**

  Accepted by IEEE **INFOCOM** 2023, **CCF‑A**         <a href="http://nju-cn.github.io/files/ResMap.pdf" style="background: red; color: white;">link</a>         <a href="http://nju-cn.github.io/files/Infocom2023.pptx" style="background: blue; color: white;">slides</a>         <a href="https://github.com/nju-cn/ResMap" style="background: orange; color: white;">code</a>

  **Ning Chen**, Shuai Zhang, Sheng Zhang, Yuting Yan, Yu Chen and Sanglu Lu.

* **Cuttlefish: Neural Configuration Adaptation for Video Analysis in live Augmented Reality**

  Accepted by IEEE **TPDS** 2021, **CCF-A**         <a href="http://nju-cn.github.io/files/Cuttlefish_TPDS.pdf" style="background: red; color: white;">link</a>         <a href="http://nju-cn.github.io/files/Cuttlefish.pptx" style="background: blue; color: white;">slides</a>         <a href="https://github.com/nju-cn/Cuttlefish" style="background: orange; color: white;">code</a>

  **Ning Chen**, Siyi Quan, Sheng Zhang, Zhuzhong Qian, Yibo Jin, Jie Wu, Wenzhong Li, Sanglu Lu. 

  

## **CONTACT**

**Name:** Ning Chen （陈宁）

**Address:** Soochow University, Science and Technology Experiment Building, 430

**Email:** ningc@suda.edu.cn

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=_JrSqe6LHWABefXTXh3X68RPF-N4Xh31ywvL7P24xAE&cl=ffffff&w=a"></script>